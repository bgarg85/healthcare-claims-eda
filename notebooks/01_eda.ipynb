{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7da6e228",
   "metadata": {},
   "source": [
    "# HC01 — Healthcare Claims EDA Notebook\n",
    "Author: Bhanu Garg  \n",
    "Created: 2025-09-03 03:08:40\n",
    "\n",
    "_Goal: Load claims, members, and providers data; perform basic cleaning; derive useful columns; join; explore; and visualize._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a166e9c",
   "metadata": {},
   "source": [
    "## 1) Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4ed75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Do NOT use seaborn. We stick to matplotlib as per project conventions.\n",
    "import os, sys, math, json, textwrap\n",
    "from datetime import datetime, date\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make pandas output easier to read\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 120)\n",
    "\n",
    "print('Python', sys.version)\n",
    "print('Pandas', pd.__version__)\n",
    "print('NumPy', np.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d573c7",
   "metadata": {},
   "source": [
    "## 2) Configure File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a88aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adjust paths if your repo structure differs\n",
    "DATA_DIR = '../data'  # if this notebook lives in notebooks/\n",
    "CLAIMS_CSV = os.path.join(DATA_DIR, 'claims.csv')\n",
    "MEMBERS_CSV = os.path.join(DATA_DIR, 'members.csv')\n",
    "PROVIDERS_CSV = os.path.join(DATA_DIR, 'providers.csv')\n",
    "\n",
    "for p in [CLAIMS_CSV, MEMBERS_CSV, PROVIDERS_CSV]:\n",
    "    print(p, 'exists:', os.path.exists(p))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524b3216",
   "metadata": {},
   "source": [
    "## 3) Load CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f402df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def try_read_csv(path, parse_date_cols=None):\n",
    "    parse_date_cols = parse_date_cols or []\n",
    "    try:\n",
    "        df = pd.read_csv(path, parse_dates=[c for c in parse_date_cols if c in pd.read_csv(path, nrows=1).columns])\n",
    "        print(f'✅ Loaded: {path} -> shape={df.shape}')\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f'⚠️ File not found: {path}')\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f'⚠️ Error reading {path}: {e}')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "claims  = try_read_csv(CLAIMS_CSV, parse_date_cols=['service_date', 'claim_date', 'paid_date'])\n",
    "members = try_read_csv(MEMBERS_CSV, parse_date_cols=['dob'])\n",
    "providers = try_read_csv(PROVIDERS_CSV)\n",
    "\n",
    "def peek(df, name):\n",
    "    print(f'\\n{name} head:')\n",
    "    display(df.head(3))\n",
    "    print(f'{name} dtypes:')\n",
    "    print(df.dtypes)\n",
    "    print(f'{name} columns:', list(df.columns))\n",
    "\n",
    "peek(claims, 'claims')\n",
    "peek(members, 'members')\n",
    "peek(providers, 'providers')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355e8ee7",
   "metadata": {},
   "source": [
    "## 4) Basic Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93830162",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def standardize_columns(df):\n",
    "    # Strip, lower, replace spaces with underscores\n",
    "    df.columns = [c.strip().lower().replace(' ', '_') for c in df.columns]\n",
    "    return df\n",
    "\n",
    "claims = standardize_columns(claims)\n",
    "members = standardize_columns(members)\n",
    "providers = standardize_columns(providers)\n",
    "\n",
    "# Deduplicate by common IDs if present\n",
    "for df, name, key in [(claims, 'claims', 'claim_id'), (members, 'members', 'member_id'), (providers, 'providers', 'provider_id')]:\n",
    "    if key in df.columns:\n",
    "        before = len(df)\n",
    "        df.drop_duplicates(subset=[key], inplace=True)\n",
    "        after = len(df)\n",
    "        if before != after:\n",
    "            print(f'ℹ️ Deduped {name} on {key}: {before} -> {after}')\n",
    "\n",
    "# Handle obvious empty strings as NaN\n",
    "for df in [claims, members, providers]:\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == object:\n",
    "            df[col] = df[col].replace({'': np.nan, 'NA': np.nan, 'N/A': np.nan})\n",
    "\n",
    "print('✅ Basic cleaning complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1232c4df",
   "metadata": {},
   "source": [
    "## 5) Derive Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26b25dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# year_month from service_date/claim_date if available\n",
    "def add_year_month(df, date_cols=('service_date','claim_date')):\n",
    "    for c in date_cols:\n",
    "        if c in df.columns and np.issubdtype(df[c].dtype, np.datetime64):\n",
    "            df['year_month'] = df[c].dt.to_period('M').astype(str)\n",
    "            print(f'✅ Derived year_month from {c}')\n",
    "            return df\n",
    "    print('⚠️ No datetime column found among', date_cols, '— skipped year_month.')\n",
    "    return df\n",
    "\n",
    "def compute_age_years(members_df, asof_col=None):\n",
    "    # If dob and as-of date available (e.g., claim service_date), compute age\n",
    "    if 'dob' not in members_df.columns:\n",
    "        print('⚠️ members.dob missing — skipping age computation.')\n",
    "        return members_df\n",
    "    # If asof_col is supplied and exists, use it post-join; otherwise skip for now.\n",
    "    members_df['birth_year'] = members_df['dob'].dt.year\n",
    "    return members_df\n",
    "\n",
    "claims = add_year_month(claims)\n",
    "members = compute_age_years(members)\n",
    "\n",
    "# Normalize dollar amounts if present\n",
    "for amt_col in ['billed_amount','allowed_amount','paid_amount']:\n",
    "    if amt_col in claims.columns:\n",
    "        # Remove currency symbols/commas\n",
    "        if claims[amt_col].dtype == object:\n",
    "            claims[amt_col] = claims[amt_col].str.replace('[\\$,]', '', regex=True)\n",
    "        claims[amt_col] = pd.to_numeric(claims[amt_col], errors='coerce')\n",
    "\n",
    "print('✅ Derivations done.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c5e725",
   "metadata": {},
   "source": [
    "## 6) Join Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7172b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Attempt joins if keys exist\n",
    "joined = claims.copy()\n",
    "join_keys = []\n",
    "\n",
    "if 'member_id' in claims.columns and 'member_id' in members.columns:\n",
    "    joined = joined.merge(members.add_prefix('m_'), left_on='member_id', right_on='m_member_id', how='left')\n",
    "    join_keys.append('member_id')\n",
    "if 'provider_id' in claims.columns and 'provider_id' in providers.columns:\n",
    "    joined = joined.merge(providers.add_prefix('p_'), left_on='provider_id', right_on='p_provider_id', how='left')\n",
    "    join_keys.append('provider_id')\n",
    "\n",
    "print('Joined on keys:', join_keys if join_keys else 'none (using claims only)')\n",
    "display(joined.head(3))\n",
    "print('joined shape:', joined.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb600157",
   "metadata": {},
   "source": [
    "## 7) Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06f5d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def summarize(df):\n",
    "    out = {}\n",
    "    out['n_rows'] = len(df)\n",
    "    for col in ['claim_id', 'member_id', 'provider_id']:\n",
    "        if col in df.columns:\n",
    "            out[f'n_unique_{col}'] = df[col].nunique()\n",
    "    if 'paid_amount' in df.columns:\n",
    "        out['total_paid'] = float(np.nansum(df['paid_amount'].values))\n",
    "        out['avg_paid'] = float(np.nanmean(df['paid_amount'].values))\n",
    "    if 'billed_amount' in df.columns:\n",
    "        out['total_billed'] = float(np.nansum(df['billed_amount'].values))\n",
    "    if 'status' in df.columns:\n",
    "        # assuming values like 'Denied', 'Paid', etc.\n",
    "        denom = len(df[df['status'].notna()])\n",
    "        if denom > 0:\n",
    "            out['denial_rate'] = float((df['status'].astype(str).str.lower().eq('denied')).mean())\n",
    "    return pd.Series(out)\n",
    "\n",
    "summary_claims = summarize(claims)\n",
    "summary_joined = summarize(joined)\n",
    "\n",
    "print('Claims summary:')\n",
    "display(summary_claims.to_frame('value'))\n",
    "print('Joined summary:')\n",
    "display(summary_joined.to_frame('value'))\n",
    "\n",
    "# Save a quick profile\n",
    "profile = pd.concat([summary_claims.rename('claims'), summary_joined.rename('joined')], axis=1)\n",
    "profile_path = '../artifacts/eda_profile_summary.csv'\n",
    "os.makedirs(os.path.dirname(profile_path), exist_ok=True)\n",
    "profile.to_csv(profile_path)\n",
    "print('📄 Saved profile to', profile_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdde337d",
   "metadata": {},
   "source": [
    "## 8) Visuals (matplotlib only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca302a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8.1 Distribution of paid amount\n",
    "if 'paid_amount' in claims.columns:\n",
    "    plt.figure()\n",
    "    claims['paid_amount'].dropna().plot(kind='hist', bins=50, alpha=0.7)\n",
    "    plt.title('Distribution of Paid Amount')\n",
    "    plt.xlabel('paid_amount')\n",
    "    plt.ylabel('frequency')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('⚠️ paid_amount not found — skipping histogram.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f45eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8.2 Monthly paid trend\n",
    "if 'year_month' in claims.columns and 'paid_amount' in claims.columns:\n",
    "    monthly = claims.groupby('year_month', as_index=False)['paid_amount'].sum().sort_values('year_month')\n",
    "    plt.figure()\n",
    "    plt.plot(monthly['year_month'], monthly['paid_amount'])\n",
    "    plt.title('Monthly Total Paid')\n",
    "    plt.xlabel('year_month')\n",
    "    plt.ylabel('total_paid')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('⚠️ year_month or paid_amount missing — skipping monthly trend.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b51ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8.3 Top providers by total paid\n",
    "provider_name_col = None\n",
    "for cand in ['provider_name','name','p_provider_name','p_name']:\n",
    "    if cand in joined.columns:\n",
    "        provider_name_col = cand\n",
    "        break\n",
    "\n",
    "if provider_name_col and 'paid_amount' in joined.columns:\n",
    "    topN = joined.groupby(provider_name_col, as_index=False)['paid_amount'].sum().sort_values('paid_amount', ascending=False).head(10)\n",
    "    plt.figure()\n",
    "    plt.bar(topN[provider_name_col], topN['paid_amount'])\n",
    "    plt.title('Top 10 Providers by Total Paid')\n",
    "    plt.xlabel('provider')\n",
    "    plt.ylabel('total_paid')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('⚠️ provider name column or paid_amount missing — skipping top providers chart.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779930e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8.4 Denial rate by month (if status + year_month present)\n",
    "if 'status' in claims.columns and 'year_month' in claims.columns:\n",
    "    tmp = claims.copy()\n",
    "    tmp['is_denied'] = tmp['status'].astype(str).str.lower().eq('denied').astype(int)\n",
    "    dr = tmp.groupby('year_month', as_index=False)['is_denied'].mean()\n",
    "    plt.figure()\n",
    "    plt.plot(dr['year_month'], dr['is_denied'])\n",
    "    plt.title('Denial Rate by Month')\n",
    "    plt.xlabel('year_month')\n",
    "    plt.ylabel('denial_rate')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('⚠️ status or year_month missing — skipping denial rate chart.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251b1286",
   "metadata": {},
   "source": [
    "## 9) Next Steps & TODOs\n",
    "\n",
    "- [ ] Validate column names in your CSVs and update key names if needed (`claim_id`, `member_id`, `provider_id`, `service_date`, `paid_amount`, etc.).\n",
    "- [ ] Add a proper data dictionary under `../docs/data_dictionary.md`.\n",
    "- [ ] Explore cohorts (e.g., member age bands vs. denial rate).\n",
    "- [ ] Add unit tests for simple data quality checks (row counts, null rates).\n",
    "- [ ] Capture screenshots of key charts for the README.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
